{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/glincow/llm-examples/blob/main/Prompt_Engineering_techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RasjCay5dhK"
      },
      "source": [
        "# Getting Started with Prompt Engineering\n",
        "by DAIR.AI | Elvis Saravia\n",
        "\n",
        "\n",
        "This notebook contains examples and exercises to learning about prompt engineering.\n",
        "\n",
        "We will be using the [OpenAI APIs](https://platform.openai.com/) for all examples. I am using the default settings `temperature=0.7` and `top-p=1`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbbQUVYS5dhO"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FQ6LNyQ5dhP"
      },
      "source": [
        "## 1. Prompt Engineering Basics\n",
        "\n",
        "Objectives\n",
        "- Load the libraries\n",
        "- Review the format\n",
        "- Cover basic prompts\n",
        "- Review common use cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSGavsM75dhP"
      },
      "source": [
        "Below we are loading the necessary libraries, utilities, and configurations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wVAYk1vA5dhQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# update or install the necessary libraries\n",
        "!pip install --upgrade openai\n",
        "!pip install --upgrade langchain\n",
        "!pip install --upgrade python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PjIcz7Io5dhR"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "import IPython\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "#from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp3guO2a5dhR"
      },
      "source": [
        "Load environment variables. You can use anything you like but I used `python-dotenv`. Just create a `.env` file with your `OPENAI_API_KEY` then load it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wJVJLLtV5dhS"
      },
      "outputs": [],
      "source": [
        "#load_dotenv()\n",
        "\n",
        "# API configuration\n",
        "#openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# for LangChain\n",
        "#os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "from google.colab import userdata\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LrgW_sae5dhS"
      },
      "outputs": [],
      "source": [
        "def set_open_params(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=256,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "):\n",
        "    \"\"\" set openai parameters\"\"\"\n",
        "\n",
        "    openai_params = {}\n",
        "\n",
        "    openai_params['model'] = model\n",
        "    openai_params['temperature'] = temperature\n",
        "    openai_params['max_tokens'] = max_tokens\n",
        "    openai_params['top_p'] = top_p\n",
        "    openai_params['frequency_penalty'] = frequency_penalty\n",
        "    openai_params['presence_penalty'] = presence_penalty\n",
        "    return openai_params\n",
        "\n",
        "def get_completion(params, messages):\n",
        "    \"\"\" GET completion from openai api\"\"\"\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model = params['model'],\n",
        "        messages = messages,\n",
        "        temperature = params['temperature'],\n",
        "        max_tokens = params['max_tokens'],\n",
        "        top_p = params['top_p'],\n",
        "        frequency_penalty = params['frequency_penalty'],\n",
        "        presence_penalty = params['presence_penalty'],\n",
        "    )\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JAnkuUG5dhT"
      },
      "source": [
        "Basic prompt example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Z1hf3P_95dhT"
      },
      "outputs": [],
      "source": [
        "# basic example\n",
        "params = set_open_params()\n",
        "\n",
        "prompt = \"The sky is\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8SqxSoJd5dhU",
        "outputId": "61e876aa-800c-4b4d-8ab6-ca326fb6d5e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' blue and dotted with fluffy white clouds.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJR6Pgz_5dhV"
      },
      "source": [
        "Try with different temperature to compare results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "5CwnjNB45dhV",
        "outputId": "e01d34a5-8377-4dd4-92a5-eee93e51c9b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " always beautiful, whether it's soft pale blue or cloaked in darkness.totalCount are no limits to the wonders and mystery it holds, from fluffy white clouds to dazzling galaxies. It reminds us of the vastness of the universe and of the ever-changing beauty of the world around us."
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "params = set_open_params(temperature=1.7)\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95i3Xinv5dhV"
      },
      "source": [
        "### 1.1 Text Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "wXJNFYGY5dhV",
        "outputId": "6c8da577-4337-44f7-dbe7-f1d97860e7ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Antibiotics are special medicines that help our bodies fight off bad germs, but we can only use them when a doctor says it's okay."
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "params = set_open_params(temperature=0.7)\n",
        "prompt = \"\"\"Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the body's immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance.\n",
        "\n",
        "Explain the above in one sentence like I am 5:\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xx70Dt25dhV"
      },
      "source": [
        "Exercise: Instruct the model to explain the paragraph in one sentence like \"I am 5\". Do you see any differences?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03X9Ef145dhW"
      },
      "source": [
        "### 1.2 Question Answering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "Hv__gCn15dhW",
        "outputId": "a8238f01-6592-44ea-b912-0c0983863446"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Unsure about answer"
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "prompt = \"\"\"Answer the question based on the context below. Keep the answer short and concise. Respond \"Unsure about answer\" if not sure about the answer.\n",
        "\n",
        "Context: Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3. Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential. In 1986, it was approved to help prevent organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.\n",
        "\n",
        "Question: What is Chronicles of Amber?\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Gnoa6U85dhW"
      },
      "source": [
        "Context obtained from here: https://www.nature.com/articles/d41586-023-00400-x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USeA2-GZ5dhW"
      },
      "source": [
        "Exercise: Edit prompt and get the model to respond that it isn't sure about the answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiSTIT_D5dhW"
      },
      "source": [
        "### 1.3 Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "kmMHB5nq5dhW",
        "outputId": "ece2e396-d6fe-402f-d285-6056bcd75a84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Neutral\n\nExplanation: The text does not express a strong positive or negative opinion about the food, indicating a neutral sentiment. The use of the word \"okay\" suggests that the person found the food to be average or satisfactory, but not particularly good or bad."
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "prompt = \"\"\"Classify the text into neutral, negative or positive. Provide an explanation about your answer.\n",
        "\n",
        "Text: I think the food was okay.\n",
        "\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr0xgr6r5dhX"
      },
      "source": [
        "Exercise: Modify the prompt to instruct the model to provide an explanation to the answer selected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG84EeIz5dhX"
      },
      "source": [
        "### 1.4 Role Playing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "CX5LUtl35dhX",
        "outputId": "c1d3af01-962c-4097-db41-bc0a92dcd70b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Certainly! Black holes are formed when a massive star runs out of fuel and collapses under its own gravity. This collapse causes the star's core to condense into an extremely dense and compact region known as a singularity. The gravitational pull of this singularity is so strong that not even light can escape, creating what we call a black hole."
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "prompt = \"\"\"The following is a conversation with an AI research assistant. The assistant tone is technical and scientific.\n",
        "\n",
        "Human: Hello, who are you?\n",
        "AI: Greeting! I am an AI research assistant. How can I help you today?\n",
        "Human: Can you tell me about the creation of blackholes?\n",
        "AI:\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G123UyxD5dhX"
      },
      "source": [
        "Exercise: Modify the prompt to instruct the model to keep AI responses concise and short."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOUOm4ua5dhX"
      },
      "source": [
        "### 1.5 Code Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51YkoY6J5dhX",
        "outputId": "3ef2dcd4-11fd-4a7f-a592-934b07098285"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "SELECT StudentName\n",
              "FROM students\n",
              "WHERE DepartmentId = (SELECT DepartmentId FROM departments WHERE DepartmentName = 'Computer Science')"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"\\\"\\\"\\\"\\nTable departments, columns = [DepartmentId, DepartmentName]\\nTable students, columns = [DepartmentId, StudentId, StudentName]\\nCreate a MySQL query for all students in the Computer Science Department\\n\\\"\\\"\\\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJH3nM3i5dhX"
      },
      "source": [
        "### 1.6 Reasoning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gGxyHuv5dhX",
        "outputId": "fc75db9f-e5a8-431e-c0a5-96ee714aa64f"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "To solve this problem, we need to follow these steps:\n",
              "\n",
              "Step 1: Identify the odd numbers in the given group. The odd numbers in the group are 15, 5, 13, 7, and 1.\n",
              "\n",
              "Step 2: Add the odd numbers together. 15 + 5 + 13 + 7 + 1 = 41.\n",
              "\n",
              "Step 3: Determine whether the sum is odd or even. In this case, the sum is 41, which is an odd number.\n",
              "\n",
              "Therefore, the sum of the odd numbers in the given group is an odd number."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"\"\"The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
        "\n",
        "Solve by breaking the problem into steps. First, identify the odd numbers, add them, and indicate whether the result is odd or even.\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-k4yFoi5dhY"
      },
      "source": [
        "Exercise: Improve the prompt to have a better structure and output format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh4q36dX5dhY"
      },
      "source": [
        "## 2. Advanced Prompting Techniques\n",
        "\n",
        "Objectives:\n",
        "\n",
        "- Cover more advanced techniques for prompting: few-shot, chain-of-thoughts,..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-EI7Ijl5dhY"
      },
      "source": [
        "### 2.2 Few-shot prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "_DeasR-w5dhY",
        "outputId": "7633ee07-a516-4a03-bc46-723495b9026c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'get_completion' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-018cba93eeff>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m ]\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_completion' is not defined"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
        "A: The answer is False.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.\n",
        "A: The answer is True.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 16,  11, 14, 4, 8, 13, 24.\n",
        "A: The answer is True.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\n",
        "A: The answer is False.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
        "A:\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJnUFEcm5dhY"
      },
      "source": [
        "### 2.3 Chain-of-Thought (CoT) Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGgJcNQz5dhY",
        "outputId": "cfd403ef-34ee-48fb-830c-fb5566670827"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Adding all the odd numbers (15, 5, 13, 7, 1) gives 41. The answer is False."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"\"\"The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
        "A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
        "A:\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vHnnPgl5dhY"
      },
      "source": [
        "### 2.4 Zero-shot CoT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lGd7sap5dhZ",
        "outputId": "a597906e-ae60-43dc-d06b-9cbdaedbeace"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Step 1: Bought 10 apples.\n",
              "Step 2: Gave 2 apples to the neighbor and 2 apples to the repairman.\n",
              "Remaining apples: 10 - 2 - 2 = 6 apples.\n",
              "Step 3: Bought 5 more apples.\n",
              "Total apples now: 6 + 5 = 11 apples.\n",
              "Step 4: Ate 1 apple.\n",
              "Remaining apples: 11 - 1 = 10 apples.\n",
              "\n",
              "Final answer: You remained with 10 apples."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"\"\"I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?\n",
        "\n",
        "Let's think step by step.\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)\n",
        "IPython.display.Markdown(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6fMDQ_A5dhi"
      },
      "source": [
        "### 2.5 Self-Consistency\n",
        "As an exercise, check examples in our [guide](https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/guides/prompts-advanced-usage.md#self-consistency) and try them here.\n",
        "\n",
        "### 2.6 Generate Knowledge Prompting\n",
        "\n",
        "As an exercise, check examples in our [guide](https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/guides/prompts-advanced-usage.md#generated-knowledge-prompting) and try them here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48THDCDR5dhi"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "promptlecture",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "f38e0373277d6f71ee44ee8fea5f1d408ad6999fda15d538a69a99a1665a839d"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}